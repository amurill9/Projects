{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S6C8MvcaMHGf"
   },
   "source": [
    "# CSE 146 Lab 3: Algorithmic Fairness\n",
    "\n",
    "### ASSIGNED: Tueday, October 20\n",
    "### DUE: Tuesday, October 29\n",
    "### 100 points total\n",
    "\n",
    "In this homework, you will gain experience with tools for implementing classifiers that provide fairness guarantees. In part 2, you will try to get a fair classifier if you only have access to a normal classifier. In parts 3 and 4, you will get to explore the different outcomes when using different definitions of fairness for classifiers. You will also look at the tradeoffs between fairness and accuracy. \n",
    "\n",
    "All cells where code is required are marked with a \"# YOUR CODE HERE\" comment. All cells where a written answer is required are marked with \"Please type your answers here!\". The point values for each code block are written in the header for the associated subsection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N33PR9c0MHGi"
   },
   "source": [
    "## Instructions \n",
    "For each question, you should write Python code to compute the answer to the questions that renders in a readable way according to the specifications of the question. You may only use the packages provided in the Background and Setup code. We will not be installing any packages during grading, and code that does not compile will negatively affect your grade.\n",
    "\n",
    "This assignment can be done collaboratively, and please be sure to list the student(s) you worked with in the space provided below. Please reach out to each other if you have any questions or difficulties.\n",
    "\n",
    "Be sure to rename this homework notebook (in [YOUR NAME HERE] so that it includes your name. \n",
    "\n",
    "### List the student(s) you worked with on this assignment here:\n",
    "1. Zachary Zulanas\n",
    "2. [person 2]\n",
    "3. [etc.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cAHEbLv5MHGk"
   },
   "source": [
    "## Part 1: Importing Data (5 Points)\n",
    "Before working with the algorithms for fair classification, we must first import the dataset we wish to use. We will again be working with the \"Communities and Crime\" dataset from [UC Irvine's Machine Learning Repository](http://archive.ics.uci.edu/ml/datasets/communities+and+crime). It includes data about the different types of crimes among various communities, socioeconomic and racial data about each community, and information about the police force in each community.\n",
    "\n",
    "The algorithms will require that your data is split into 3 DataFrames:\n",
    "\n",
    "- `dataX`: The features of each instance, not including any protected attributes\n",
    "- `dataA`: The protected attributes of each instance\n",
    "- `dataY`: The label for each instance (the value to be predicted)\n",
    "\n",
    "Currently, we provide you with 2 CSV files:\n",
    "\n",
    "- `communities.csv`, which contains all information for each instance\n",
    "- `communities_protected.csv`, which is a single-row dataframe, indicating how each column within `communities.csv` should be used. If the column value is 0 the attribute is unprotected, if its 1 the attribute is a protected feature, and 2 if the attribute is the value to be predicted (the label for each instance).\n",
    "\n",
    "In part 2, we will focus on only one of the protected features. In parts 3 and 4, we will use all 18 protected features for upholding our fairness metrics.\n",
    "\n",
    "Write code to generate the 3 Pandas DataFrames, `dataX`, `dataA` and `dataY`. \n",
    "\n",
    "*Hint: Remember how we checked for DataFrame values in Lab1 via dataframe[dataframe == some_val], and read pandas' .dropna() function for dataframes!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_4d_D5IQMHGm"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SWmpeHEqMHG1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd # Necessary libraries\n",
    "import numpy as np\n",
    "import warnings # Suppressing warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "32Pu7DDEMHHM"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "dataframe = pd.read_csv(\"communities.csv\")\n",
    "mask  = pd.read_csv(\"communities_protected.csv\")\n",
    "\n",
    "dataX = dataframe.loc[:,(mask!=1).any()]\n",
    "dataA = dataframe.loc[:,(mask==1).any()]\n",
    "\n",
    "dataY = dataX[['ViolentCrimesPerPop']]\n",
    "dataX = dataX.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uDFMY9CQMHHf"
   },
   "outputs": [],
   "source": [
    "print('dataX Shape:', dataX.shape)\n",
    "print('dataA Shape:', dataA.shape)\n",
    "print('dataY Shape:', dataY.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfJ-SyxwMHHy"
   },
   "source": [
    "## Part 2: Two-Group Fairness via Post-processing (35 Points)\n",
    "\n",
    "In this section, you will implement a method of achieving a fair classifier \"from scratch\" by post-processing a generic linear regression classifier. If you'd like to read about it in depth, this method is described in depth in https://arxiv.org/abs/1610.02413. \n",
    "\n",
    "You will train a classifier which approximately equalizes both True Positive Rate and False Positive Rate for two groups, which is commonly referred to as the Equalized Odds criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FskTQOBiMHH2"
   },
   "source": [
    "### 2.1: Training a Real-Valued Predictor (5 points)\n",
    "\n",
    "So far we've been working with classifiers that predict 0 or 1 scores. There are also models, like linear regression, that predict real-values scores. For now, you can think of these real-valued scores as the estimated probability that that instance's classification should be 1.\n",
    "\n",
    "Now, you will train a real-valued predictor. Use the Linear Regression package from SciKit-Learn to train a regression model on dataX and dataY. Generate predictions for dataY (called y_hat_score) and print them. \n",
    "\n",
    "NOTE: Please make sure to do a train/test split, as this is a general practice in machine learning.\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XaJJk0k3MHH5"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "lin = linear_model.LinearRegression()\n",
    "\n",
    "split = 1400\n",
    "\n",
    "dataX_train = dataX.iloc[:split,:].copy()\n",
    "dataX_test  = dataX.iloc[split:,:].copy()\n",
    "dataY_train = dataY.iloc[:split,:].copy()\n",
    "dataY_test  = dataY.iloc[split:,:].copy()\n",
    "\n",
    "lin.fit(dataX_train,dataY_train)\n",
    "\n",
    "y_hat_score = lin.predict(dataX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e-MwZoRmMHIF"
   },
   "outputs": [],
   "source": [
    "print(y_hat_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SQdrur0uMHIV"
   },
   "source": [
    "### 2.2: Binary Classification via Thresholding (5 points)\n",
    "\n",
    "We will need to convert our estimated probabilities to 0/1 predictions. Write a function (named threshold_predictions) which takes in a set of predicted linear regression scores, a threshold, and converts the scores to 0/1 predictions (below or equal to threshold $\\to$ 0, above threshold $\\to$ 1). Print out your converted predictions using a threshold of 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yVyvNYGTMHIW"
   },
   "outputs": [],
   "source": [
    "def threshold_predictions(y_hat_score, threshold):\n",
    "    y_hat_0_1 = y_hat_score.copy()\n",
    "    for i in range(0, y_hat_0_1.shape[0]):\n",
    "        if y_hat_0_1[i,0] <= threshold:\n",
    "            y_hat_0_1[i,0] = 0\n",
    "        else:\n",
    "            y_hat_0_1[i,0] = 1\n",
    "    return y_hat_0_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67fIG1-LMHIe"
   },
   "outputs": [],
   "source": [
    "y_hat_0_1 = threshold_predictions(y_hat_score, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xS9Dt0shMHIm"
   },
   "source": [
    "### 2.3: Computing TPR and FPR (5 points)\n",
    "\n",
    "There are many peformance measurements for machine learning classifiers. We now introduce two new ones, true positive rate and false positive rate. We define them using the terminology from a confusion matrix:\n",
    "\n",
    "\\begin{equation}\n",
    "TruePosRate = \\frac{True Positive}{True Positive + False Negative}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "FalsePosRate = \\frac{False Positive}{False Positive + True Negative}\n",
    "\\end{equation}\n",
    "\n",
    "Write functions which compute the true positive rate and false positive rate, given vectors for true labels (y) and binary predictions (y_hat).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KpiP5bLjMHIo"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def true_positive_rate(y, y_hat):\n",
    "    true_positive  = 0\n",
    "    false_negative = 0\n",
    "    for i in range(0, y.shape[0]):\n",
    "        if y[i,0] == 1:\n",
    "            if y_hat[i,0] == 1:\n",
    "                true_positive  += 1\n",
    "            else:\n",
    "                false_negative += 1\n",
    "    return ((true_positive)/(true_positive+false_negative))\n",
    "\n",
    "def false_positive_rate(y, y_hat):\n",
    "    true_negative  = 0\n",
    "    false_positive = 0\n",
    "    for i in range(0, y.shape[0]):\n",
    "        if y[i,0] == 0:\n",
    "            if y_hat[i,0] == 0:\n",
    "                true_negative  += 1\n",
    "            else:\n",
    "                false_positive += 1\n",
    "    return ((false_positive)/(false_positive+true_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j_iw0FhuMHI6"
   },
   "source": [
    "Now, we compute the TPR and FPR for your predictions from 2.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jhoZi2Z6MHI9"
   },
   "outputs": [],
   "source": [
    "print(true_positive_rate(dataY_test.values, y_hat_0_1))\n",
    "print(false_positive_rate(dataY_test.values, y_hat_0_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KpD8xGAQMHJM"
   },
   "source": [
    "### 2.4: Computing ROC Curves (5 points)\n",
    "\n",
    "ROC (receiver operating characteristic) curves measure the tradeoff between true positive and false positive rates when thresholding a real-valued predictor. We discussed them in class, but this statquest video can be helpful: https://www.youtube.com/watch?v=4jRBRDbJemM\n",
    "\n",
    "Write a function that:\n",
    "- takes in a set of true labels in {0,1} (such as dataY), a set of predictions within interval [0,1] (such as y_hat_score), and a single integer `num_thresholds`, representing the number of thresholds. \n",
    "- Evenly divide the range [0,1] into `num_thresholds` equally sized intervals. (For example, if num_thresholds = 100, your thresholds should be 0.00, 0.01, 0.02, ... , 0.99.) \n",
    "- For each interval, using the bottom of the interval as a threshold,  compute the TPR and FPR of the thresholded predictions.\n",
    "\n",
    "Then, using your function, compute TPR and FPR arrays for `dataY`, `y_hat_score` and `num_thresholds` at 100. (Hint: see numpy's `arange` function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "igjw9xooMHJN"
   },
   "outputs": [],
   "source": [
    "def compute_roc_curve(y, y_hat_score, num_thresholds):\n",
    "    # Your code here\n",
    "    tpr = np.zeros(num_thresholds)\n",
    "    fpr = np.zeros(num_thresholds)\n",
    "\n",
    "    for i in range(0, num_thresholds):\n",
    "        y_hat_0_1 = threshold_predictions(y_hat_score,i/num_thresholds)\n",
    "        fpr[i]    = false_positive_rate(y,y_hat_0_1)\n",
    "        tpr[i]    = true_positive_rate(y,y_hat_0_1)\n",
    "    # End of your code\n",
    "    return tpr, fpr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GSG5YRBSMHJb"
   },
   "outputs": [],
   "source": [
    "tpr, fpr = compute_roc_curve(dataY_test.values, y_hat_score, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaNl_-FGMHJk"
   },
   "source": [
    "### 2.5: ROC Curve Comparison (5 points)\n",
    "\n",
    "The code below is copied from our solution to Lab 1. It splits the data into two groups (A and B) based on whether the proportion of some attribute is greater than some threshold. We use it to split our data depending on whether the proportion of African American people in a community is greater than 50%. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gwj8HAmXMHJm"
   },
   "outputs": [],
   "source": [
    "## RUN THIS CELL\n",
    "## DO NOT MODIFY\n",
    "\n",
    "def split_on_feature(dataX, dataY, dataA, column, thresh):\n",
    "    rows_A = []\n",
    "    rows_B = []\n",
    "    for i in range(dataX.shape[0]):\n",
    "        if dataA[i, column] < thresh:\n",
    "            rows_A.append(i)\n",
    "        else:\n",
    "            rows_B.append(i)\n",
    "    \n",
    "    X_A = dataX[rows_A, :]\n",
    "    X_B = dataX[rows_B, :]\n",
    "    y_A = dataY[rows_A]\n",
    "    y_B = dataY[rows_B]\n",
    "    \n",
    "    return X_A, X_B, y_A, y_B  \n",
    "\n",
    "\n",
    "# change 2 to whatever racepctblack is\n",
    "X_A, X_B, y_A, y_B = split_on_feature(dataX.values, dataY.values, dataA.values, 0, 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rS9NAbxgMHJ8"
   },
   "source": [
    "Using the generated arrays (X_A, X_B, y_A, y_B) and your function from 2.4, produce a matplotlib plot showing the ROC curves for each group with 100 threshold values. Use your trained linear regression model for predictions. Your X axis should be FPR and your Y axis should be TPR. Refer to Homework 1 for a reminder on how to use matplotlib."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hhGWa--qMHJ-"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## YOUR CODE HERE\n",
    "\n",
    "y_A_hat = lin.predict(X_A)\n",
    "y_B_hat = lin.predict(X_B)\n",
    "\n",
    "tpr_A, fpr_A = compute_roc_curve(y_A, y_A_hat, 100)\n",
    "tpr_B, fpr_B = compute_roc_curve(y_B, y_B_hat, 100)\n",
    "\n",
    "plt.title('ROC Curve')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "\n",
    "plt.plot(fpr_A, tpr_A, color='blue', label='A curve')\n",
    "plt.plot(fpr_B, tpr_B, color='red' , label='B curve')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-IniOiiMHKH"
   },
   "source": [
    "### 2.6: Minimizing Unfairness (5 points)\n",
    "\n",
    "There are many, many different definitions of unfairness. For this lab, we'll be using the **Equalized Odds Criterion**, where we check if the ROC curves of two groups are the same. We check its \"fairness error\" via: $|TPR_A - TPR_B| + |FPR_A - FPR_B|$\n",
    "\n",
    "There are 10,000 possible pairs of thresholds of the form $(a,b)$ where $a$ is the threshold for A and $b$ is the threshold for B in data plotted above. Find and print out the pair of thresholds which minimizes this \"fairness error\". (Graphiaclly, this translates to finding points which are closest between the two ROC curves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "onLnzIegMHKM"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "min_unfairness_A_thresh = 100\n",
    "min_unfairness_B_thresh = 100\n",
    "min_error = 100\n",
    "for j in range(0 , 100):\n",
    "    for i in range (0 , 100):\n",
    "        equalized_error = (abs(tpr_A[i]-tpr_B[j])+abs(fpr_A[i]-fpr_B[j]))\n",
    "        if min_error > equalized_error:\n",
    "            min_error = equalized_error\n",
    "            min_unfairness_A_thresh = i/100\n",
    "            min_unfairness_B_thresh = j/100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "inEgDRR2MHKb"
   },
   "outputs": [],
   "source": [
    "print((min_unfairness_A_thresh, min_unfairness_B_thresh))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GsxOBch6MHKo"
   },
   "source": [
    "### 2.7: Evaluating Accuracy (5 points)\n",
    "\n",
    "Compute `fair_acc`, the overall accuracy when using the thresholds from 2.6 on their respective groups. Compare this `max_acc`, to the single-value threshold in {0.00, 0.01, 0.02, ... , 0.99} that maximizes overall accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4suPdux7MHKr"
   },
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "\n",
    "def acc(y,y_hat):\n",
    "    true_value = 0\n",
    "    for i in range(0, y.shape[0]):\n",
    "        if y[i,0] == y_hat[i,0]:\n",
    "            true_value += 1\n",
    "    return (true_value)/(y.shape[0])\n",
    "\n",
    "fair_acc_A = acc(y_A,threshold_predictions(y_A_hat,min_unfairness_A_thresh))\n",
    "fair_acc_B = acc(y_B,threshold_predictions(y_B_hat,min_unfairness_B_thresh))\n",
    "fair_acc   = (fair_acc_A + fair_acc_B)/2\n",
    "\n",
    "max_acc    = 0\n",
    "\n",
    "y_hat_ = lin.predict(dataX)\n",
    "for i in range (0,100):\n",
    "    y_hat_temp  = threshold_predictions(y_hat_,i/100)\n",
    "    temp_acc    = acc(dataY.values, y_hat_temp)\n",
    "    if temp_acc > max_acc:\n",
    "        max_acc = temp_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bse7iaEIMHKy"
   },
   "outputs": [],
   "source": [
    "print((fair_acc,max_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9C2UmvWUMHK-"
   },
   "source": [
    "## Part 3: Equalized Odds vs. Demographic Parity (30 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pgS8q_32MHLA"
   },
   "source": [
    "In this section, we will revisit the equalized odds criterion and investigate further. Specifically, we will compare this fairness metric to another one -- demographic parity. This comparison will give us some insight into how various fairness metrics may or may not interact with each other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8UbU_6jjMHLC"
   },
   "source": [
    "### 3.1 Revisit Equalized Odds (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pFggSSTcMHLD"
   },
   "source": [
    "In the previous problem, you plotted the fairness error of the equalized odds criterion for two thresholds, one for each group. Now, we want just one threshold, therefore we need to have the error computed that is associated with each group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YLz4HcI-MHLE"
   },
   "source": [
    "For each threshold $(0.00, 0.01... 0.99)$, compute the equalized odds unfairness from part 2. Make sure to save these results in a specified variable. Note: it's important that the ordering of this array is the same as the threshold array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HX2jUNyRMHLF"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "equalized_odds = np.zeros(100)\n",
    "\n",
    "for i in range(0, 100):\n",
    "    equalized_odds[i] = abs(tpr_A[i]-tpr_B[i])+abs(fpr_A[i]-fpr_B[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHxycD0HMHLV"
   },
   "source": [
    "### 3.2 Demographic Parity (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juQ7cT6XMHLW"
   },
   "source": [
    "Intuitively demographic parity says that the ratio of the group in the whole population will be the same as the ratio of the group in the predicted classes. Formally for protected attribute $G$ and classifier $\\hat{Y}$, this can be specified as $$ P(G = g | \\hat{Y} = y) = P(G = g).$$\n",
    "\n",
    "The demographic parity unfairness can be computed as $$ \\sum_{g, y} | P(G = g | \\hat{Y} = y) - P(G = g) | .$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zz9LG5i7MHLY"
   },
   "source": [
    "Write a function to compute the demographic parity error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0ToHOhosMHLa"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "def demographic_parity_error(y_hat_a,y_hat_b):\n",
    "    error_A = np.unique(y_hat_a, return_counts=True)\n",
    "    error_B = np.unique(y_hat_, return_counts=True)\n",
    "    \n",
    "    d_p_e =  abs(error_A[1][0]/(error_A[1][0] + error_B[1][0]) - (y_hat_a.shape[0]/dataY.shape[0]))\n",
    "    \n",
    "    d_p_e += abs(error_B[1][0]/(error_A[1][0] + error_B[1][0]) - (y_hat_b.shape[0]/dataY.shape[0]))\n",
    "    \n",
    "    d_p_e += abs(error_A[1][1]/(error_A[1][1] + error_B[1][1]) - (y_hat_a.shape[0]/dataY.shape[0]))\n",
    "    \n",
    "    d_p_e += abs(error_B[1][1]/(error_A[1][1] + error_B[1][1]) - (y_hat_b.shape[0]/dataY.shape[0]))\n",
    "\n",
    "    return d_p_e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pKJegyQ2MHLi"
   },
   "source": [
    "Write a function that computes an array of demographic parity errors given a list of thresholds. Note: The thresholds need to be all in the same order as the equalized odds thresholds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YQopgoYlMHLl"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "dem_parity = np.zeros(100)\n",
    "\n",
    "for i in range(0,100):\n",
    "    threshold_A   = threshold_predictions(y_A_hat,i/100)\n",
    "    threshold_B   = threshold_predictions(y_B_hat,i/100)\n",
    "    dem_parity[i] = demographic_parity_error(threshold_A, threshold_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dLSfiq4eMHLy"
   },
   "source": [
    "### 3.3 Combine Equalized Odds & Demographic Parity (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzIsI-WTMHLz"
   },
   "source": [
    "Now that you have computed the errors for both fairness metrics -- equalized odds and demographic parity -- we can investigate further into our comparison, which will be achieved by correlating the error for both. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCw3LPwPMHL0"
   },
   "source": [
    "Currently, both errors exist as 'columns', or vectors. We would like to combine them into a single matrix $[equalized\\:odds\\:error, demographic\\:parity\\:error]$. \n",
    "\n",
    "Sort the row of the matrix in ascending order according to the equalized odds error. This ordering will enable us to complete the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9auzYtxxMHL1"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "sorted_eo = equalized_odds.copy()\n",
    "sorted_eo.sort()\n",
    "sorted_dp = dem_parity.copy()\n",
    "sorted_dp.sort()\n",
    "combined_eo_dp = np.stack((sorted_eo,sorted_dp),axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Y0FAYHOMHME"
   },
   "source": [
    "### 3.4 Visualization of Equalized Odds vs. Demographic Parity (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBlAUKd2MHMF"
   },
   "source": [
    "Now, we want to visualize this comparison. Plot the two rows of the matrix (from 3.3) as two separate line graphs. When plotted, you will notice a particular trend, specifically in the direction of the lines for equalized odds and demographic parity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBUfixsOMHMH"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VcDNDjqEMHMS"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "plt.title('Visualization of Equalized Odds vs. Demographic Parity')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Error')\n",
    "\n",
    "thresholds = np.zeros(100)\n",
    "for i in range(0,100):\n",
    "    thresholds[i] = i/100\n",
    "\n",
    "plt.plot(thresholds, combined_eo_dp[0], color='blue', label='Equalized Odds')\n",
    "plt.plot(thresholds, combined_eo_dp[1], color='red' , label='Demographic Parity')\n",
    "\n",
    "plt.grid(True)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EnN-Z9lGMHMf"
   },
   "source": [
    "### 3.5 Now You Pick! (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMM0OVUAMHMh"
   },
   "source": [
    "From this [Towards Data Science article](https://towardsdatascience.com/a-tutorial-on-fairness-in-machine-learning-3ff8ba1040cb), choose another definition of fairness. Explain here why you are interested in investigating this definition, and mention a scenario where it could be violated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46CXXMOSMHMk"
   },
   "source": [
    "Please type your answers here!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NIUiIhTKMHMv"
   },
   "source": [
    "Now, just like you did earlier in part 3, plot this error against those for demographic parity and equalized odds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHJ0jJczMHMx"
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n",
    "def predictive_parity(y_hat_a, y_hat_b):\n",
    "    error_A = np.unique(y_hat_a, return_counts=True)\n",
    "    error_B = np.unique(y_hat_b, return_counts=True)\n",
    "    \n",
    "    p_p_e  = abs(error_A[1][0]/(y_hat_a.shape[0]) - ((error_A[1][0] + error_B[1][0])/dataY.shape[0]))\n",
    "    \n",
    "    p_p_e += abs(error_A[1][1]/(y_hat_a.shape[0]) - ((error_A[1][0] + error_B[1][0])/dataY.shape[0]))\n",
    "    \n",
    "    p_p_e += abs(error_B[1][0]/(y_hat_b.shape[0]) - ((error_A[1][1] + error_B[1][1])/dataY.shape[0]))\n",
    "    \n",
    "    p_p_e += abs(error_B[1][1]/(y_hat_b.shape[0]) - ((error_A[1][1] + error_B[1][1])/dataY.shape[0]))  \n",
    "        \n",
    "    return p_p_e\n",
    "\n",
    "pred_error = np.zeros(100)\n",
    "\n",
    "\n",
    "for i in range(0,100):\n",
    "    threshold_A   = threshold_predictions(y_A_hat,i/100)\n",
    "    threshold_B   = threshold_predictions(y_B_hat,i/100)\n",
    "    pred_error[i] = predictive_parity(threshold_A,threshold_B)\n",
    "    \n",
    "\n",
    "\n",
    "plt.title('Visualization of Errors')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Error')\n",
    "\n",
    "thresholds = np.zeros(100)\n",
    "for i in range(0,100):\n",
    "    thresholds[i] = i/100\n",
    "\n",
    "pred_error.sort()\n",
    "    \n",
    "plt.plot(thresholds, combined_eo_dp[0], color='blue', label='Equalized Odds')\n",
    "plt.plot(thresholds, combined_eo_dp[1], color='red' , label='Demographic Parity')\n",
    "plt.plot(thresholds, pred_error, color='green' , label='Predictive Parity')\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cet5tVzhMHNE"
   },
   "source": [
    "## Part 4: Short Response Questions (30 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WBGWuVIuMHNF"
   },
   "source": [
    "**Question 1 (5 points):** Below is a gif of a heatmap which shows how false positive disparity change for specific subgroups as the Learner and Auditor interact in each round. Each square represents a subgroup, the z-axis is the fairness disparity of that subgroup. What does it mean when the heatmap is \\\"flat\\\"?\n",
    "![heatmap](./heatmap.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kAR_fYpmMHNH"
   },
   "source": [
    "The higher the overall flow means that the fairness is unbalanced. When the graph is flat horizontally then we have a balance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t1oq7TfUMHNI"
   },
   "source": [
    "**Question 2 (5 points):** In Part 2, you should have seen that the accuracy for the fair thresholds was much larger than the error the accuracy-maximizing threshold. Suppose that you are allowed to randomize between thresholds (randomly switch between thresholding on fairness and thresholding on accurate thresholds). Is this a smart approach to maximizing accuracy while maintaining fairness? Can you think of a better approach?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRnVDQehMHNK"
   },
   "source": [
    "The accuracy for fair thresholds wasn't larger than the accuracy-maximizing threshold. I would say that while it would maximize accuracy it would lower the fairness of the model. A much better approach is to pick a threshold that has an overal best scenario for both fairness and accuracy, trying to keep them as balanced as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EWU165JtMHNL"
   },
   "source": [
    "**Question 3 (5 points):** What is the relationship between error of a fair classifier and the number of protected attributes? That is, if we increase the number of protected attributes, would you expect the error to increase, decrease, or stay the same?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "26wnBwCOMHNN"
   },
   "source": [
    "The number of protected attributes increases error in two ways. First, by having less features to analyze with the algorithm the model is less accurate, as it may be underfitted. Second, as shown before, having protected attributes may increase fairness, but at the cost of overall accuracy, as the model has to adapt to a less accurate model that respects the fairness."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N7Nc4vUsMHNP"
   },
   "source": [
    "**Question 4 (5 points):** Was accuracy a good measure to evaluate each threshold in part 2.7? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqsZ_62_MHNR"
   },
   "source": [
    "It is important to always calculate the accuracy because it gives an understanding as to how effective the algorithm was at creating a model that correctly predicts the data. While accuracy is important, it shouldn't be the only measure to be taken into account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K0AOQdoOMHNT"
   },
   "source": [
    "**Question 5 (5 points):** Take a look at your plot from 3.4. Thinking of the trends in the two lines, what is the relationship between equalized odds and demographic parity? What could this possibly mean for how fairness measures interact in general?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bvKx3EoEMHNU"
   },
   "source": [
    "Both errors increase as the thresholds increase, but for large thresholds the equalized odds error seems to be much higher. They seem to interact with each other, as they comlement each other to paint the whole picture of what is happending."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C8Ly-82dMHNW"
   },
   "source": [
    "**Question 6 (5 points):** Provide an interpretation of your plot from 3.5. Keep in mind again the trends of the two lines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CBaLyC1MHNX"
   },
   "source": [
    "Apparently, my predictive parity error mas much higher than my other errors. Also, it has a similar growth to that of the demographic parity error. This is because while very fair, the predictive parity approach lacks severely in accuracy when compared to other approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "KpD8xGAQMHJM",
    "EaNl_-FGMHJk",
    "j-IniOiiMHKH",
    "GsxOBch6MHKo",
    "8UbU_6jjMHLC",
    "kHxycD0HMHLV",
    "dLSfiq4eMHLy",
    "4Y0FAYHOMHME",
    "EnN-Z9lGMHMf"
   ],
   "name": "CSE146_Lab3--[YOURNAMEHERE]_2020.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
